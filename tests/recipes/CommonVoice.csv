Task,Dataset,Script_file,Hparam_file,Data_prep_file,Readme_file,Result_url,HF_repo,test_debug_flags,test_debug_checks,performance
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_en_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/scl/fo/gx0szpbectig2r6r6p9vk/APdoN_wWWq_wP4My7w6SvMo?rlkey=v8fhd887bn947yjb45i99wm8p&st=6muft51b&dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=21 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/21_char.model,save/ASR_train.txt,save/21_char.vocab]",Test-WER=16.16%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_fr_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/0i7esfa8jp3rxpp/AAArdi8IuCRmob2WAS7lg6M4a?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-fr,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=21 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/21_char.model,save/ASR_train.txt,save/21_char.vocab]",Test-WER=9.71%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_it_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/hthxqzh5boq15rn/AACftSab_FM6EFWWPgHpKw82a?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-it,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=7.99%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_rw_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/4iax0l4yfry37gn/AABuQ31JY-Sbyi1VlOJfV7haa?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-rw,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=22.52%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_de_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/dn7plq4wfsujsi1/AABS1kqB_uqLJVkg-bFkyPpVa?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-de,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --output_neurons=21 --skip_prep=True --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/21_char.model,save/ASR_train.txt,save/21_char.vocab]",Test-WER=8.39%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_ar_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/7tnuqqbr4vy96cc/AAA_5_R0RmqFIiyR0o1nVS4Ia?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-ar,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=28.53%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_es_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/ejvzgl3d3g8g9su/AACYtbSWbDHvBr06lAb7A4mVa?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-es,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=12.67%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_pt_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/80wucrvijdvao2a/AAD6-SZ2_ZZXmlAjOTw6fVloa?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-pt,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=21.69%
ASR-CTC,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_zh-CN_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://www.dropbox.com/sh/2bikr81vgufoglf/AABMpD0rLIaZBxjtwBHgrNpga?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-14-zh-CN,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_log.txt,log.txt,wer_test.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/27_unigram.vocab,save/ASR_train.txt,save/27_unigram.model]",Test-WER=23.17%
ASR-seq2seq,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_de.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://www.dropbox.com/sh/zgatirb118f79ef/AACmjh-D94nNDWcnVI4Ef5K7a?dl=0,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-14-de,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]","file_exists=[train_log.txt,log.txt,wer_test.txt,env.log,train.py,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=12.25%
ASR-seq2seq,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_en.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://www.dropbox.com/sh/h8ged0yu3ztypkh/AAAu-12k_Ceg-tTjuZnrg7dza?dl=0,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-14-en,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]","file_exists=[train_log.txt,log.txt,wer_test.txt,env.log,train.py,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=23.88%
ASR-seq2seq,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_fr.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://www.dropbox.com/sh/07a5lt21wxp98x5/AABhNwmWFaNFyA734bNZUO03a?dl=0,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-14-fr,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]","file_exists=[train_log.txt,log.txt,wer_test.txt,env.log,train.py,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=14.88%
ASR-seq2seq,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_it.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://www.dropbox.com/sh/ss59uu0j5boscvp/AAASsiFhlB1nDWPkFX410bzna?dl=0,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-14-it,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]","file_exists=[train_log.txt,log.txt,wer_test.txt,env.log,train.py,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=17.02%
ASR-seq2seq,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_rw.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://www.dropbox.com/sh/i1fv4f8miilqgii/AAB3gE97kmFDA0ISkIDSUW_La?dl=0,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-14-rw,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]","file_exists=[train_log.txt,log.txt,wer_test.txt,env.log,train.py,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=29.22%
ASR-seq2seq,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_es.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://www.dropbox.com/sh/r3w0b2tm1p73vft/AADCxdhUwDN6j4PVT9TYe-d5a?dl=0,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-14-es,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]","file_exists=[train_log.txt,log.txt,wer_test.txt,train.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=14.77%
ASR-transducer,CommonVoice,recipes/CommonVoice/ASR/transducer/train.py,recipes/CommonVoice/ASR/transducer/hparams/conformer_transducer.yaml,recipes/CommonVoice/ASR/transducer/common_voice_prepare.py,recipes/CommonVoice/ASR/transducer/README.md,https://www.dropbox.com/scl/fo/kue72ik3vc55xu6u8zjr7/h?rlkey=ie98ktqf9gbunn4x9i3pskedq&dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27,"file_exists=[train_log.txt,log.txt,wer_test.txt,train.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",
ASR-transformer,CommonVoice,recipes/CommonVoice/ASR/transformer/train.py,recipes/CommonVoice/ASR/transformer/hparams/conformer_large.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --d_model=128 --num_encoder_layers=3 --num_decoder_layers=3 --d_ffn=256,"file_exists=[train_log.txt,log.txt,wer_test.txt,train.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",
ASR-transformer,CommonVoice,recipes/CommonVoice/ASR/transformer/train.py,recipes/CommonVoice/ASR/transformer/hparams/mwmha_transformer_large.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://1drv.ms/f/c/039f8ffe91e06416/Et7KEbSlWNdJhkjLIi7_vGQBMVhGwRRBzCSljh6aA4sJSw?e=dXeuiY,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=78 --skip_prep=True --output_neurons=5120 --d_model=512 --num_encoder_layers=24 --num_decoder_layers=6 --d_ffn=2048,"file_exists=[train_log.txt,log.txt,wer_test.txt,train.py,env.log,hyperparams.yaml,save/27_unigram.model,save/ASR_train.txt,save/27_unigram.vocab]",Test-WER=13.69%
ASR-transformer,CommonVoice,recipes/CommonVoice/ASR/transformer/train_with_whisper.py,recipes/CommonVoice/ASR/transformer/hparams/train_hf_whisper.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=1 --skip_prep=True --whisper_hub=openai/whisper-tiny,"file_exists=[train_with_whisper.py,wer_valid.txt,train_log.txt,log.txt,wer_test.txt,env.log,hyperparams.yaml]",Test-WER=16.96%
SSL,CommonVoice,recipes/CommonVoice/self-supervised-learning/wav2vec2/train_hf_wav2vec2.py,recipes/CommonVoice/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml,recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py,recipes/CommonVoice/self-supervised-learning/wav2vec2/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --d_model=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[train_hf_wav2vec2.py,train_log.txt,log.txt,env.log,hyperparams.yaml]",
LM,CommonVoice,recipes/CommonVoice/LM/train.py,recipes/CommonVoice/LM/hparams/train_kenlm.yaml,recipes/CommonVoice/LM/common_voice_prepare.py,recipes/CommonVoice/LM/README.md,https://www.dropbox.com/scl/fo/zw505t10kesqpvkt6m3tu/h?rlkey=6626h1h665tvlo1mtekop9rx5&dl=0,,--data_folder=tests/samples/ASR/ --text_file=tests/samples/annotation/LM_train.txt --skip_prep=True,"file_exists=[log.txt,train.py,env.log,hyperparams.yaml]",
