Task,Dataset,Script_file,Hparam_file,Data_prep_file,Readme_file,Result_url,HF_repo,test_debug_flags,test_debug_checks
Tokenizer,Tedlium2,recipes/Tedlium2/Tokenizer/train.py,recipes/Tedlium2/Tokenizer/hparams/tedlium2_500_bpe.yaml,recipes/Tedlium2/Tokenizer/tedlium2_prepare.py,recipes/Tedlium2/Tokenizer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --skip_prep=True --token_output=23 --clipped_utt_folder=None,
ASR,Tedlium2,recipes/Tedlium2/ASR/transformer/train.py,recipes/Tedlium2/ASR/transformer/hparams/branchformer_large.yaml,recipes/Tedlium2/Tokenizer/tedlium2_prepare.py,recipes/Tedlium2/ASR/transformer/README.md,,,--data_folder=. --clipped_utt_folder=. --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --output_neurons=23 --number_of_epochs=10 --skip_prep=True --pretrained_tokenizer_file=tests/tmp/Tedlium2_row_02/23_bpe.model,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]"
