Task,Dataset,Script_file,Hparam_file,Data_prep_file,Readme_file,Result_url,HF_repo,test_debug_flags,test_debug_checks,performance
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,https://www.dropbox.com/sh/qj2ps85g8oiicrj/AAAxlkQw5Pfo0M9EyHMi8iAra?dl=0,https://huggingface.co/speechbrain/asr-wav2vec2-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt] performance_check=[train_log.txt, train loss, <3.5, epoch: 10]",Test_clean-WER=1.65% Test_other-WER=3.67%
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec_transformer_rescoring.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,https://www.dropbox.com/sh/ijqalvre7mm08ng/AAD_hsN-8dBneUMMkELsOOxga?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --output_neurons=21 --number_of_epochs=2 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt]",Test_clean-WER=1.57% Test_other-WER=3.37%
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec_rnn_rescoring.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,https://www.dropbox.com/sh/k4ixa211yp5b1tm/AAD85sgYw2CH7NKk_qKMO9Tja?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --output_neurons=21 --number_of_epochs=2 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_whisper.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_whisper_encoder.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,https://www.dropbox.com/sh/zmtp13huxn02fot/AADyKL5q0MwRhEG1-WbSXDWda?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --skip_prep=True --whisper_folder=tests/tmp/whisper_checkpoint --whisper_hub=openai/whisper-tiny.en,"file_exists=[train_with_whisper.py,wer_ASR_train.txt,train_log.txt,log.txt,env.log,hyperparams.yaml,save/29_char.vocab,save/29_char.model,save/ASR_train.txt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_sb_wav2vec.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --output_neurons=21 --number_of_epochs=2 --skip_prep=True --wav2vec2_hub=speechbrain/ssl-wav2vec2-base-librispeech,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt,save/extractor.ckpt,save/encoder_wrapper.ckpt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_bestrq.py,recipes/LibriSpeech/ASR/CTC/hparams/train_sb_BEST-RQ.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --output_neurons=21 --number_of_epochs=2 --skip_prep=True --pt_model_path=null,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_bestrq.py,env.log,hyperparams.yaml,save/label_encoder.txt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_signal_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 2 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_conv_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 2 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_average_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 2 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_average_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 3 --upsampling=True --ctc_neurons=58 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_conv_downsampling.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--downsampling_factor 3 --upsampling=True --ctc_neurons=58 --data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,train_with_wav2vec.py,env.log,hyperparams.yaml,save/label_encoder.txt]",
ASR-Seq2Seq,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_1000.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,https://www.dropbox.com/sh/1ycv07gyxdq8hdl/AABUDYzza4SLYtY45RcGf2_0a?dl=0 https://www.dropbox.com/sh/a39wq3h60luv552/AABBnCM2Uf-CNax_cgMWdqDda?dl=0,https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]",
ASR-Seq2Seq,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_5000.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,https://www.dropbox.com/sh/1ycv07gyxdq8hdl/AABUDYzza4SLYtY45RcGf2_0a?dl=0,https://huggingface.co/speechbrain/asr-crdnn-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]",Test_clean-WER=2.89% Test_other-WER=8.09%
ASR-Seq2Seq,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_1000_sligru.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]",
ASR-Transducers,LibriSpeech,recipes/LibriSpeech/ASR/transducer/train.py,recipes/LibriSpeech/ASR/transducer/hparams/conformer_transducer.yaml,recipes/LibriSpeech/ASR/transducer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transducer/README.md,https://www.dropbox.com/scl/fo/kl1eikmoauygwqcx8ok4r/AMkreKLzHtxPtqnoXzUerko?rlkey=juk374k210b76lbnblh7or95d&st=1ugwe9e3&dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True --beam_size=1,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <=1000, epoch: 10]",Test_clean-WER=2.72% Test_other-WER=6.47%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/conformer_small.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/sh/s0x6ni124858b8i/AAALaCH6sGTMRUVTjh8Tm8Jwa?dl=0,https://huggingface.co/speechbrain/asr-conformersmall-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <350, epoch: 10]",Test_clean-WER=2.49% Test_other-WER=6.10%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/transformer.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/sh/653kq8h2k87md4p/AAByAaAryXtQKpRzYtzV9ih5a?dl=0,https://huggingface.co/speechbrain/asr-transformer-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <=350, epoch: 10]",Test_clean-WER=2.27% Test_other-WER=5.53%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/conformer_large.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/scl/fo/9we244tgdf47ay20hrdoz/AKnoqQ13nLwSv1ITeJEQ3wY?rlkey=05o5jiszr8rhj6dlprw87t2x4&st=u2odesyk&dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test_clean-WER=2.01% Test_other-WER=4.52%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/branchformer_large.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/scl/fo/qhtds5rrdvhhhjywa7ovw/AMiIL5YvQENw5JKVpzXlP5o?rlkey=hz8vlpy3qf9kcyfx0cox089e6&st=ufckv6tb&dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[wer_ASR_train.txt,train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt,save/lm.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test_clean-WER=2.04% Test_other-WER=4.12%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/hyperconformer_22M.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/sh/30xsmqj13jexzoh/AACvZNtX1Fsr0Wa1Z3C9rHLXa?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test_clean-WER=2.23% Test_other-WER=4.54%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/hyperconformer_8M.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/sh/8jc96avmivr8fke/AABrFEhtWy_3-Q7BHhkh0enwa?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test_clean-WER=2.55% Test_other-WER=6.61%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/hyperbranchformer_25M.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test_clean-WER=2.36% Test_other-WER=6.89%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/hyperbranchformer_13M.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test_clean-WER=2.54% Test_other-WER=6.58%
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train_with_whisper.py,recipes/LibriSpeech/ASR/transformer/hparams/train_hf_whisper.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --skip_prep=True --whisper_folder=tests/tmp/whisper_checkpoint --whisper_hub=openai/whisper-tiny.en,"file_exists=[train_with_whisper.py,wer_ASR_train.txt,train_log.txt,log.txt,env.log,hyperparams.yaml]",-
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train_with_whisper.py,recipes/LibriSpeech/ASR/transformer/hparams/train_whisper_lora.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --skip_prep=True --whisper_folder=tests/tmp/whisper_checkpoint --whisper_hub=openai/whisper-tiny.en,"file_exists=[train_with_whisper.py,wer_ASR_train.txt,train_log.txt,log.txt,env.log,hyperparams.yaml]",-
ASR-Transformers,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train_bayesspeech.py,recipes/LibriSpeech/ASR/transformer/hparams/bayesspeech.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://www.dropbox.com/scl/fo/cdken4jqfj96ev1v84jxm/h?rlkey=25eu1ytgm5ac51zqj8p65zwxd&dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train_bayesspeech.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <500, epoch: 10]",Test_clean-WER=2.84% Test_other-WER=6.27%
ASR,minilibrispeech,templates/speech_recognition/ASR/train.py,templates/speech_recognition/ASR/train.yaml,templates/speech_recognition/ASR/mini_librispeech_prepare.py,templates/speech_recognition/ASR/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_dev.json --test_annotation=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,save/lm.ckpt,save/model.ckpt,save/tokenizer.ckpt,train_log.txt,train.py,wer_test.txt,save/CKPT+latest/brain.ckpt,save/CKPT+latest/CKPT.yaml,save/CKPT+latest/counter.ckpt,save/CKPT+latest/dataloader-TRAIN.ckpt,save/CKPT+latest/model.ckpt,save/CKPT+latest/normalizer.ckpt,save/CKPT+latest/optimizer.ckpt,save/CKPT+latest/scheduler.ckpt]",
Enhancement,minilibrispeech,templates/enhancement/train.py,templates/enhancement/train.yaml,templates/enhancement/mini_librispeech_prepare.py,templates/enhancement/README.md,,,--data_folder=tests/samples/separation --train_annotation=tests/samples/annotation/enhancement_train.json --valid_annotation=tests/samples/annotation/enhancement_dev.json --test_annotation=tests/samples/annotation/enhancement_dev.json --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,save,train_log.txt,train.py]",
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train.py,recipes/LibriSpeech/G2P/hparams/hparams_g2p_rnn.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/qmcl1obp8pxqaap/AAC3yXvjkfJ3mL-RKyAUxPdNa?dl=0,,--data_folder=tests/samples/ASR/ --tokenizer_train_data=tests/samples/annotation/ASR_train.json --tokenizer_valid_data=tests/samples/annotation/ASR_dev.json --lexicon_epochs=2 --skip_prep=True --phn_token_output=42 --use_tensorboard=False --debug,"file_exists=[train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/wer_sentence.txt,save/homograph_stats.txt,save/wer_homograph.txt,save/wer_lexicon.txt,save/pretrained_models/ctc_lin.ckpt,save/pretrained_models/model.ckpt,reports/lexicon/1/wer_lexicon.txt,reports/lexicon/2/wer_lexicon.txt,reports/homograph/1/homograph_stats.txt,reports/homograph/1/wer_homograph.txt,reports/homograph/2/homograph_stats.txt,reports/homograph/2/wer_homograph.txt,reports/sentence/1/wer_sentence.txt,reports/sentence/2/wer_sentence.txt]",PER-Test=2.72%
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train.py,recipes/LibriSpeech/G2P/hparams/hparams_g2p_transformer.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/zhrxg7anuhje7e8/AADTeJtdsja_wClkE2DsF9Ewa?dl=0,https://huggingface.co/speechbrain/soundchoice-g2p,--data_folder=tests/samples/ASR/ --tokenizer_train_data=tests/samples/annotation/ASR_train.json --tokenizer_valid_data=tests/samples/annotation/ASR_dev.json --lexicon_epochs=2 --skip_prep=True --phn_token_output=42 --use_tensorboard=False --debug,"file_exists=[train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/wer_sentence.txt,save/homograph_stats.txt,save/wer_homograph.txt,save/wer_lexicon.txt,save/pretrained_models/ctc_lin.ckpt,save/pretrained_models/model.ckpt,reports/lexicon/1/wer_lexicon.txt,reports/lexicon/2/wer_lexicon.txt,reports/homograph/1/homograph_stats.txt,reports/homograph/1/wer_homograph.txt,reports/homograph/2/homograph_stats.txt,reports/homograph/2/wer_homograph.txt,reports/sentence/1/wer_sentence.txt,reports/sentence/2/wer_sentence.txt]",PER-Test=2.89%
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train_lm.py,recipes/LibriSpeech/G2P/hparams/hparams_lm_rnn.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/pig0uk80xxii7cg/AACQ1rrRLYthvpNZ5FadPLtRa?dl=0,,--data_folder=tests/samples/ASR/ --tokenizer_train_data=tests/samples/annotation/ASR_train.json --tokenizer_valid_data=tests/samples/annotation/ASR_dev.json --train_data=tests/samples/annotation/ASR_train.json --valid_data=tests/samples/annotation/ASR_dev.json --test_data=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --phn_token_output=42,"file_exists=[train_lm.py,train_log.txt,log.txt,env.log,hyperparams.yaml,save/tokenizer_annotation_train.json,save/tokenizer_annotation_valid.json,save/tokenizer_annotation_test.json,save/phoneme_annotations.txt,save/phoneme_tokenizer/42_unigram.model,save/phoneme_tokenizer/42_unigram.vocab]",
G2P,LibriSpeech,recipes/LibriSpeech/G2P/train_lm.py,recipes/LibriSpeech/G2P/hparams/hparams_lm_transformer.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://www.dropbox.com/sh/tkf6di10edpz4i6/AAArnGAkE0bEEOvOGfc6KWuma?dl=0,,--data_folder=tests/samples/ASR/ --train_data=tests/samples/annotation/ASR_train.json --valid_data=tests/samples/annotation/ASR_dev.json --test_data=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --emb_dim=64 --debug,"file_exists=[train_lm.py,train_log.txt,log.txt,env.log,hyperparams.yaml]",
LM,LibriSpeech,recipes/LibriSpeech/LM/train.py,recipes/LibriSpeech/LM/hparams/RNNLM.yaml,recipes/LibriSpeech/LM/librispeech_prepare.py,recipes/LibriSpeech/LM/README.md,https://www.dropbox.com/sh/8xpybezuv70ibcg/AAByv2NuNv_ZFXuDdG89-MVPa?dl=0 https://www.dropbox.com/sh/8462ef441wvava2/AABNfHr07J_0SsdaM1yO5qkxa?dl=0 https://www.dropbox.com/sh/6uwqlw2tvv3kiy6/AACgvTR5jihyMrugBrpZPFNha?dl=0,,--data_folder=tests/samples/annotation/ --lm_corpus_path=tests/samples/annotation/LM_train.txt.gz --train_transcripts_pattern=LM_train.txt --dev_transcripts_pattern=LM_dev.txt --test_transcripts_pattern=LM_dev.txt --number_of_epochs=2,"file_exists=[train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt]",
LM,LibriSpeech,recipes/LibriSpeech/LM/train.py,recipes/LibriSpeech/LM/hparams/transformer.yaml,recipes/LibriSpeech/LM/librispeech_prepare.py,recipes/LibriSpeech/LM/README.md,https://www.dropbox.com/sh/8xpybezuv70ibcg/AAByv2NuNv_ZFXuDdG89-MVPa?dl=0 https://www.dropbox.com/sh/8462ef441wvava2/AABNfHr07J_0SsdaM1yO5qkxa?dl=0 https://www.dropbox.com/sh/6uwqlw2tvv3kiy6/AACgvTR5jihyMrugBrpZPFNha?dl=0,,--data_folder=tests/samples/annotation/ --lm_corpus_path=tests/samples/annotation/LM_train.txt.gz --train_transcripts_pattern=LM_train.txt --dev_transcripts_pattern=LM_dev.txt --test_transcripts_pattern=LM_dev.txt --number_of_epochs=2,"file_exists=[train_log.txt,log.txt,env.log,train.py,hyperparams.yaml,save/tokenizer.ckpt]",
Tokenizer,minilibrispeech,templates/speech_recognition/Tokenizer/train.py,templates/speech_recognition/Tokenizer/tokenizer.yaml,templates/speech_recognition/Tokenizer/mini_librispeech_prepare.py,templates/speech_recognition/Tokenizer/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_train.json --test_annotation=tests/samples/annotation/ASR_train.json --skip_prep=True --token_output=24 --annotation_read=wrd,"file_exists=[env.log,hyperparams.yaml,log.txt,train.py,24_unigram.model,24_unigram.vocab,ASR_train.txt]",
LM,minilibrispeech,templates/speech_recognition/LM/train.py,templates/speech_recognition/LM/RNNLM.yaml,templates/speech_recognition/mini_librispeech_prepare.py,templates/speech_recognition/README.md,,,--data_folder=tests/samples/ASR/ --lm_train_data=tests/samples/annotation/LM_train.txt --lm_valid_data=tests/samples/annotation/LM_dev.txt --lm_test_data=tests/samples/annotation/LM_dev.txt --number_of_epochs=2 --emb_dim=64 --rnn_size=128 --tokenizer_file=tests/tmp/LibriSpeech_row_36/24_unigram.model,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py]",
Speaker_recognition,minilibrispeech,templates/hyperparameter_optimization_speaker_id/train.py,templates/hyperparameter_optimization_speaker_id/train.yaml,templates/hyperparameter_optimization_speaker_id/mini_librispeech_prepare.py,templates/hyperparameter_optimization_speaker_id/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_dev.json --test_annotation=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --n_classes=2 --emb_dim=42 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,save,train_log.txt,train.py,save/label_encoder.txt]",
Speaker_recognition,minilibrispeech,templates/speaker_id/train.py,templates/speaker_id/train.yaml,templates/speaker_id/mini_librispeech_prepare.py,templates/speaker_id/README.md,,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_dev.json --test_annotation=tests/samples/annotation/ASR_dev.json --number_of_epochs=2 --n_classes=2 --emb_dim=42 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,save,train_log.txt,train.py,save/label_encoder.txt]",
Tokenizer,LibriSpeech,recipes/LibriSpeech/Tokenizer/train.py,recipes/LibriSpeech/Tokenizer/hparams/1K_unigram_subword_bpe.yaml,recipes/LibriSpeech/Tokenizer/librispeech_prepare.py,recipes/LibriSpeech/Tokenizer/README.md,https://www.dropbox.com/sh/xyifwhyq2o7g8u8/AACVHHgXUsRUZIfrzHOccLP7a?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --skip_prep=True --token_output=23,"file_exists=[23_unigram.model,23_unigram.vocab,log.txt,ASR_train.txt,env.log,train.py,hyperparams.yaml]",
Tokenizer,LibriSpeech,recipes/LibriSpeech/Tokenizer/train.py,recipes/LibriSpeech/Tokenizer/hparams/5K_unigram_subword_bpe.yaml,recipes/LibriSpeech/Tokenizer/librispeech_prepare.py,recipes/LibriSpeech/Tokenizer/README.md,https://www.dropbox.com/sh/xyifwhyq2o7g8u8/AACVHHgXUsRUZIfrzHOccLP7a?dl=0,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --skip_prep=True --token_output=23,"file_exists=[23_unigram.model,23_unigram.vocab,log.txt,ASR_train.txt,env.log,train.py,hyperparams.yaml]",
self-supervised-learning,LibriSpeech,recipes/LibriSpeech/self-supervised-learning/BEST-RQ/train.py,recipes/LibriSpeech/self-supervised-learning/BEST-RQ/hparams/BEST-RQ.yaml,recipes/LibriSpeech/self-supervised-learning/BEST-RQ/librispeech_prepare.py,recipes/LibriSpeech/self-supervised-learning/BEST-RQ/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True,"file_exists=[train_stage_log.txt,train.py,log.txt,env.log,hyperparams.yaml]",
self-supervised-learning,LibriSpeech,recipes/LibriSpeech/self-supervised-learning/wav2vec2/train_sb_wav2vec2.py,recipes/LibriSpeech/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml,recipes/LibriSpeech/self-supervised-learning/wav2vec2/librispeech_prepare.py,recipes/LibriSpeech/self-supervised-learning/wav2vec2/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True,"file_exists=[train_stage_log.txt,train_sb_wav2vec2.py,log.txt,env.log,hyperparams.yaml]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train.py,recipes/LibriSpeech/ASR/CTC/hparams/conformer_large.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --skip_prep=True --output_neurons=21,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/21_char.model,save/21_char.vocab]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train.py,recipes/LibriSpeech/ASR/CTC/hparams/branchformer_large.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2 --skip_prep=True --output_neurons=21,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/21_char.model,save/21_char.vocab]",
ASR-CTC,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec_k2.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec_k2.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,--data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=2,"file_exists=[metric_ASR_train/wer_HL_1best.txt,train_log.txt,log.txt,train_with_wav2vec_k2.py,env.log,hyperparams.yaml]",
LM,LibriSpeech,recipes/LibriSpeech/LM/train_ngram.py,recipes/LibriSpeech/LM/hparams/train_ngram.yaml,recipes/LibriSpeech/LM/librispeech_prepare.py,recipes/LibriSpeech/LM/README.md,,,--data_folder=tests/samples/ASR/ --skip_prep=True --train_csv=tests/samples/annotation/ASR_train.csv,"file_exists=[env.log,hyperparams.yaml,log.txt,lang/words.txt,libri_lm_corpus.txt,train_ngram.py]",
