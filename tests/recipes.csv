RecipeID,Task,Dataset,Script_file,Hparam_file,Data_prep_file,Readme_file,Result_url,HF_repo,test_debug_flags,test_debug_checks
recipe0001,Command_recognition,Google-speech-commands,recipes/Google-speech-commands/train.py,recipes/Google-speech-commands/hparams/xvect.yaml,recipes/Google-speech-commands/prepare_GSC.py,recipes/Google-speech-commands/README.md,https://drive.google.com/drive/folders/1yPcXVHtrnNM0RhA_IGo8iAdezYZfoViQ?usp=sharing,https://huggingface.co/speechbrain/google_speech_command_xvector,,
recipe0002,Sisnr-estimation,REAL-M,recipes/REAL-M/sisnr-estimation/train.py,recipes/REAL-M/sisnr-estimation/hparams/pool_sisnrestimator.yaml,,recipes/REAL-M/sisnr-estimation/README.md,https://drive.google.com/drive/folders/1NGncbjvLeGfbUqmVi6ej-NH9YQn5vBmI?usp=sharing,https://huggingface.co/speechbrain/REAL-M-sisnr-estimator https://huggingface.co/speechbrain/REAL-M-sisnr-estimator-training,,
recipe0003,Enhancement,Voicebank,recipes/Voicebank/dereverb/spectral_mask/train.py,recipes/Voicebank/dereverb/spectral_mask/hparams/train.yaml,recipes/Voicebank/dereverb/spectral_mask/voicebank_revb_prepare.py,recipes/Voicebank/dereverb/spectral_mask/README.md,https://drive.google.com/drive/folders/1Bf-SL4gRpBdazBFuae3aFe0_EwL8v7jh,,,
recipe0004,Enhancement,Voicebank,recipes/Voicebank/dereverb/MetricGAN-U/train.py,recipes/Voicebank/dereverb/MetricGAN-U/hparams/train_dereverb.yaml,recipes/Voicebank/dereverb/MetricGAN-U/voicebank_revb_prepare.py,recipes/Voicebank/dereverb/MetricGAN-U/README.md,https://drive.google.com/drive/folders/1CFHE3lFYyIUWAxW8Ccx3hReACQ70qdE1,,,
recipe0005,Enhancement,Voicebank,recipes/Voicebank/MTL/ASR_enhance/train.py,recipes/Voicebank/MTL/ASR_enhance/hparams/enhance_mimic.yaml,recipes/Voicebank/MTL/ASR_enhance/voicebank_prepare.py,recipes/Voicebank/MTL/ASR_enhance/README.md,https://drive.google.com/drive/folders/1vSpQ5UREiBbTxNUjJjEpSYO8rLTPvQW_?usp=sharing,https://huggingface.co/speechbrain/mtl-mimic-voicebank,,
recipe0006,ASR+enhancement,Voicebank,recipes/Voicebank/MTL/ASR_enhance/train.py,recipes/Voicebank/MTL/ASR_enhance/hparams/robust_asr.yaml,recipes/Voicebank/MTL/ASR_enhance/voicebank_prepare.py,recipes/Voicebank/MTL/ASR_enhance/README.md,https://drive.google.com/drive/folders/1vSpQ5UREiBbTxNUjJjEpSYO8rLTPvQW_?usp=sharing,https://huggingface.co/speechbrain/mtl-mimic-voicebank,,
recipe0007,ASR+enhancement,Voicebank,recipes/Voicebank/MTL/ASR_enhance/train.py,recipes/Voicebank/MTL/ASR_enhance/hparams/pretrain_perceptual.yaml,recipes/Voicebank/MTL/ASR_enhance/voicebank_prepare.py,recipes/Voicebank/MTL/ASR_enhance/README.md,https://drive.google.com/drive/folders/1vSpQ5UREiBbTxNUjJjEpSYO8rLTPvQW_?usp=sharing,https://huggingface.co/speechbrain/mtl-mimic-voicebank,,
recipe0008,ASR,Voicebank,recipes/Voicebank/ASR/CTC/train.py,recipes/Voicebank/ASR/CTC/hparams/train.yaml,recipes/Voicebank/ASR/CTC/voicebank_prepare.py,recipes/Voicebank/ASR/CTC/README.md,https://drive.google.com/drive/folders/1diFVwth-MKKeNPJFwRdU9ItiFrupddKk?usp=sharing,,,
recipe0009,Enhancement,Voicebank,recipes/Voicebank/enhance/SEGAN/train.py,recipes/Voicebank/enhance/SEGAN/hparams/train.yaml,recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py,recipes/Voicebank/enhance/SEGAN/README.md,https://drive.google.com/drive/folders/1gLxbH59LpMJFhvGHLPsVlX_MP2lcwVC8?usp=sharing,,,
recipe0010,Enhancement,Voicebank,recipes/Voicebank/enhance/MetricGAN/train.py,recipes/Voicebank/enhance/MetricGAN/hparams/train.yaml,recipes/Voicebank/enhance/MetricGAN/voicebank_prepare.py,recipes/Voicebank/enhance/MetricGAN/README.md,https://drive.google.com/drive/folders/1IV3ohFracK0zLH-ZGb3LTas-l3ZDFDPW?usp=sharing,https://huggingface.co/speechbrain/metricgan-plus-voicebank,,
recipe0011,Enhancement,Voicebank,recipes/Voicebank/enhance/spectral_mask/train.py,recipes/Voicebank/enhance/spectral_mask/hparams/train.yaml,recipes/Voicebank/enhance/spectral_mask/voicebank_prepare.py,recipes/Voicebank/enhance/spectral_mask/README.md,https://drive.google.com/drive/folders/1IV3ohFracK0zLH-ZGb3LTas-l3ZDFDPW?usp=sharing,,,
recipe0012,Enhancement,Voicebank,recipes/Voicebank/enhance/waveform_map/train.py,recipes/Voicebank/enhance/waveform_map/hparams/train.yaml,recipes/Voicebank/enhance/waveform_map/voicebank_prepare.py,recipes/Voicebank/enhance/waveform_map/README.md,,,,
recipe0013,Enhancement,Voicebank,recipes/Voicebank/enhance/MetricGAN-U/train.py,recipes/Voicebank/enhance/MetricGAN-U/hparams/train_dnsmos.yaml,recipes/Voicebank/enhance/MetricGAN-U/voicebank_prepare.py,recipes/Voicebank/enhance/MetricGAN-U/README.md,https://drive.google.com/drive/folders/14KpZnUhnCAhoeRDwbIBu_zTq26y7BZdt,,,
recipe0014,Separation,LibriMix,recipes/LibriMix/separation/train.py,recipes/LibriMix/separation/hparams/sepformer-libri3mix.yaml,recipes/LibriMix/separation/dynamic_mixing.py,recipes/LibriMix/separation/README.md ,https://drive.google.com/drive/folders/1DN49LtAs6cq1X0jZ8tRMlh2Pj6AecClz?usp=sharing,,,
recipe0015,Separation,LibriMix,recipes/LibriMix/separation/train.py,recipes/LibriMix/separation/hparams/sepformer-libri2mix.yaml,recipes/LibriMix/separation/dynamic_mixing.py,recipes/LibriMix/separation/README.md ,https://drive.google.com/drive/folders/1NPTXw4i9Vmahhr5BSQQa-ZTTm45FwYJA?usp=sharing,,,
recipe0016,LM,KsponSpeech,recipes/KsponSpeech/LM/train.py,recipes/KsponSpeech/LM/hparams/transformer.yaml,recipes/KsponSpeech/LM/ksponspeech_prepare.py,recipes/KsponSpeech/LM/README.md,https://drive.google.com/drive/folders/1NmpE7aThLogxVhPrpWqFcw1dzd-fqzVA?usp=sharing,,,
recipe0017,Tokenizer,KsponSpeech,recipes/KsponSpeech/Tokenizer/train.py,recipes/KsponSpeech/Tokenizer/hparams/5K_unigram_subword_bpe.yaml,recipes/KsponSpeech/Tokenizer/ksponspeech_prepare.py,recipes/KsponSpeech/Tokenizer/README.md,https://drive.google.com/drive/folders/1zNGKDvHlLjQdUPrqP66vpD5RN9IIX6RC?usp=sharing,,,
recipe0018,ASR,KsponSpeech,recipes/KsponSpeech/ASR/transformer/train.py,recipes/KsponSpeech/ASR/transformer/hparams/conformer_medium.yaml,recipes/KsponSpeech/ASR/transformer/ksponspeech_prepare.py,recipes/KsponSpeech/ASR/transformer/README.md,https://drive.google.com/drive/folders/1iPzuhaKIUeKtOunkBkhc_sGlk47Awe80?usp=sharing,https://huggingface.co/speechbrain/asr-conformer-transformerlm-ksponspeech,,
recipe0019,Tokenizer,AISHELL-1,recipes/AISHELL-1/Tokenizer/train.py,recipes/AISHELL-1/Tokenizer/hparams/tokenizer_bpe5000.yaml,recipes/AISHELL-1/Tokenizer/aishell_prepare.py,recipes/AISHELL-1/Tokenizer/README.md,https://drive.google.com/drive/folders/15wOIkFMHB-wwR1OW6NupcLcHbiJZJ_CU?usp=sharing,,,
recipe0020,Tokenizer,AISHELL-1,recipes/AISHELL-1/Tokenizer/train.py,recipes/AISHELL-1/Tokenizer/hparams/train_transformer_tokenizer_bpe5000.yaml,recipes/AISHELL-1/Tokenizer/aishell_prepare.py,recipes/AISHELL-1/Tokenizer/README.md,https://drive.google.com/drive/folders/15wOIkFMHB-wwR1OW6NupcLcHbiJZJ_CU?usp=sharing,,,
recipe0021,ASR,AISHELL-1,recipes/AISHELL-1/ASR/transformer/train.py,recipes/AISHELL-1/ASR/transformer/hparams/train_ASR_transformer.yaml,recipes/AISHELL-1/ASR/transformer/aishell_prepare.py,recipes/AISHELL-1/ASR/transformer/README.md,https://drive.google.com/drive/folders/1xKo_6Pxk0saPXjGZg8um68b_l0Tgfdjy?usp=sharing,https://huggingface.co/speechbrain/asr-transformer-aishell,,
recipe0022,ASR,AISHELL-1,recipes/AISHELL-1/ASR/transformer/train_with_wav2vect.py,recipes/AISHELL-1/ASR/transformer/hparams/train_ASR_transformer_with_wav2vect.yaml,recipes/AISHELL-1/ASR/transformer/aishell_prepare.py,recipes/AISHELL-1/ASR/transformer/README.md,https://drive.google.com/drive/folders/1xKo_6Pxk0saPXjGZg8um68b_l0Tgfdjy?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-transformer-aishell,,
recipe0023,ASR,AISHELL-1,recipes/AISHELL-1/ASR/seq2seq/train.py,recipes/AISHELL-1/ASR/seq2seq/hparams/train.yaml,recipes/AISHELL-1/ASR/seq2seq/aishell_prepare.py,recipes/AISHELL-1/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/1zlTBib0XEwWeyhaXDXnkqtPsIBI18Uzs?usp=sharing,,,
recipe0024,Separation,WSJ0Mix,recipes/WSJ0Mix/separation/train.py,recipes/WSJ0Mix/separation/hparams/convtasnet.yaml,recipes/WSJ0Mix/separation/dynamic_mixing.py,recipes/WSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/12_Df4zsRW18YvD4hPAJAT9y_mVWnNyBm?usp=sharing,,,
recipe0025,Separation,WSJ0Mix,recipes/WSJ0Mix/separation/train.py,recipes/WSJ0Mix/separation/hparams/dprnn.yaml,recipes/WSJ0Mix/separation/dynamic_mixing.py,recipes/WSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/1Olq2077mXKqtqHluxECn1lMKIbo7xPFu?usp=sharing,,,
recipe0026,Separation,WSJ0Mix,recipes/WSJ0Mix/separation/train.py,recipes/WSJ0Mix/separation/hparams/sepformer.yaml,recipes/WSJ0Mix/separation/dynamic_mixing.py,recipes/WSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/11ulM8NqLYle6vNNZb3NvPRPHR5Rrl-FF?usp=sharing,https://huggingface.co/speechbrain/sepformer-wsj02mix https://huggingface.co/speechbrain/sepformer-wsj03mix,,
recipe0027,Separation,WSJ0Mix,recipes/WSJ0Mix/separation/train.py,recipes/WSJ0Mix/separation/hparams/sepformer-customdataset.yaml,recipes/WSJ0Mix/separation/dynamic_mixing.py,recipes/WSJ0Mix/separation/README.md,,,,
recipe0028,SLU,timers-and-such,recipes/timers-and-such/multistage/train.py,recipes/timers-and-such/multistage/hparams/train_LS_LM.yaml,recipes/timers-and-such/multistage/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,,,
recipe0029,SLU,timers-and-such,recipes/timers-and-such/multistage/train.py,recipes/timers-and-such/multistage/hparams/train_TAS_LM.yaml,recipes/timers-and-such/multistage/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,,,
recipe0030,LM,timers-and-such,recipes/timers-and-such/LM/train.py,recipes/timers-and-such/LM/hparams/train.yaml,recipes/timers-and-such/LM/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,,,
recipe0031,Tokenizer,timers-and-such,recipes/timers-and-such/Tokenizer/train.py,recipes/timers-and-such/Tokenizer/hparams/tokenizer_bpe51.yaml,recipes/timers-and-such/Tokenizer/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,,,
recipe0032,SLU,timers-and-such,recipes/timers-and-such/direct/train_with_wav2vec2.py,recipes/timers-and-such/direct/hparams/train_with_wav2vec2.yaml,recipes/timers-and-such/direct/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,,,
recipe0033,SLU,timers-and-such,recipes/timers-and-such/direct/train.py,recipes/timers-and-such/direct/hparams/train.yaml,recipes/timers-and-such/direct/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,https://huggingface.co/speechbrain/slu-timers-and-such-direct-librispeech-asr,,
recipe0034,SLU,timers-and-such,recipes/timers-and-such/decoupled/train.py,recipes/timers-and-such/decoupled/hparams/train_LS_LM.yaml,recipes/timers-and-such/decoupled/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,,,
recipe0035,SLU,timers-and-such,recipes/timers-and-such/decoupled/train.py,recipes/timers-and-such/decoupled/hparams/train_TAS_LM.yaml,recipes/timers-and-such/decoupled/prepare.py,recipes/timers-and-such/README.md,https://drive.google.com/drive/folders/1x2crmemZj2uxdzyOM_nlfuHxlTCP-9_-,,,
recipe0036,Speaker_recognition,VoxCeleb,recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py,recipes/VoxCeleb/SpeakerRec/hparams/verification_ecapa.yaml,recipes/VoxCeleb/SpeakerRec/voxceleb_prepare.py,recipes/VoxCeleb/SpeakerRec/README.md,,,,
recipe0037,Speaker_recognition,VoxCeleb,recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py,recipes/VoxCeleb/SpeakerRec/hparams/train_ecapa_tdnn.yaml,recipes/VoxCeleb/SpeakerRec/voxceleb_prepare.py,recipes/VoxCeleb/SpeakerRec/README.md,https://drive.google.com/drive/folders/1TLKByLRkgkUiDV2coMrIh-OMHANrnOl-?usp=sharing https://drive.google.com/file/d/1EziERcHD_gyE6qc8DbxPKU1isVf7pbNl/view?usp=sharing,https://huggingface.co/speechbrain/spkrec-ecapa-voxceleb,,
recipe0038,Speaker_recognition,VoxCeleb,recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py,recipes/VoxCeleb/SpeakerRec/hparams/verification_plda_xvector.yaml,recipes/VoxCeleb/SpeakerRec/voxceleb_prepare.py,recipes/VoxCeleb/SpeakerRec/README.md,,,,
recipe0039,Speaker_recognition,VoxCeleb,recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py,recipes/VoxCeleb/SpeakerRec/hparams/train_x_vectors.yaml,recipes/VoxCeleb/SpeakerRec/voxceleb_prepare.py,recipes/VoxCeleb/SpeakerRec/README.md,https://drive.google.com/drive/folders/1TLKByLRkgkUiDV2coMrIh-OMHANrnOl-?usp=sharing https://drive.google.com/file/d/1EziERcHD_gyE6qc8DbxPKU1isVf7pbNl/view?usp=sharing  https://drive.google.com/file/d/1EziERcHD_gyE6qc8DbxPKU1isVf7pbNl/view?usp=sharing,https://huggingface.co/speechbrain/spkrec-xvect-voxceleb,,
recipe0040,Diarization,AMI,recipes/AMI/Diarization/experiment.py,recipes/AMI/Diarization/hparams/ecapa_tdnn.yaml,recipes/AMI/Diarization/ami_prepare.py,recipes/AMI/Diarization/README.md,,,,
recipe0041,Diarization,AMI,recipes/AMI/Diarization/experiment.py,recipes/AMI/Diarization/hparams/xvectors.yaml,recipes/AMI/Diarization/ami_prepare.py,recipes/AMI/Diarization/README.md,,,,
recipe0042,Tokenizer,fluent-speech-commands,recipes/fluent-speech-commands/Tokenizer/train.py,recipes/fluent-speech-commands/Tokenizer/hparams/tokenizer_bpe51.yaml,recipes/fluent-speech-commands/Tokenizer/prepare.py,recipes/fluent-speech-commands/README.md,https://drive.google.com/drive/folders/13t2PYdedrPQoNYo_QSf6s04WXu2_vAb-?usp=sharing,https://huggingface.co/speechbrain/slu-direct-fluent-speech-commands-librispeech-asr,,
recipe0043,SLU,fluent-speech-commands,recipes/fluent-speech-commands/direct/train.py,recipes/fluent-speech-commands/direct/hparams/train.yaml,recipes/fluent-speech-commands/direct/prepare.py,recipes/fluent-speech-commands/README.md,https://drive.google.com/drive/folders/13t2PYdedrPQoNYo_QSf6s04WXu2_vAb-?usp=sharing,,,
recipe0044,Separation,Aishell1Mix,recipes/Aishell1Mix/separation/train.py,recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix3-wham.yaml,recipes/Aishell1Mix/separation/dynamic_mixing.py recipes/Aishell1Mix/prepare_data.py recipes/LibriMix/separation/train.py,recipes/Aishell1Mix/separation/README.md,https://drive.google.com/drive/folders/1GvJiUxhdN5bfbuBdxclPzdAPd2op1PCZ?usp=sharing,,,
recipe0045,Separation,Aishell1Mix,recipes/Aishell1Mix/separation/train.py,recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix3.yaml,recipes/Aishell1Mix/separation/dynamic_mixing.py recipes/Aishell1Mix/prepare_data.py recipes/LibriMix/separation/train.py,recipes/Aishell1Mix/separation/README.md,https://drive.google.com/drive/folders/1GvJiUxhdN5bfbuBdxclPzdAPd2op1PCZ?usp=sharing,,,
recipe0046,Separation,Aishell1Mix,recipes/Aishell1Mix/separation/train.py,recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix2.yaml,recipes/Aishell1Mix/separation/dynamic_mixing.py recipes/Aishell1Mix/prepare_data.py recipes/LibriMix/separation/train.py,recipes/Aishell1Mix/separation/README.md,https://drive.google.com/drive/folders/1GvJiUxhdN5bfbuBdxclPzdAPd2op1PCZ?usp=sharing,,,
recipe0047,Separation,Aishell1Mix,recipes/Aishell1Mix/separation/train.py,recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix2-wham.yaml,recipes/Aishell1Mix/separation/dynamic_mixing.py recipes/Aishell1Mix/prepare_data.py recipes/LibriMix/separation/train.py,recipes/Aishell1Mix/separation/README.md,https://drive.google.com/drive/folders/1GvJiUxhdN5bfbuBdxclPzdAPd2op1PCZ?usp=sharing,,,
recipe0048,SSL,CommonVoice,recipes/CommonVoice/self-supervised-learning/wav2vec2/train_hf_wav2vec2.py,recipes/CommonVoice/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml,recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py,recipes/CommonVoice/self-supervised-learning/wav2vec2/README.md,,,,
recipe0049,ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train.py,recipes/CommonVoice/ASR/transformer/hparams/train_fr.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0050,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_fr_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0051,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_fr.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-fr,,
recipe0052,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_it_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-it,,
recipe0053,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_de.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-de,,
recipe0054,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_rw.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0055,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_en.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0056,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_en_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-en,,
recipe0057,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_rw_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-rw,,
recipe0058,ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_it.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-it,,
recipe0059,ASR,CommonVoice,recipes/CommonVoice/ASR/transducer/train.py,recipes/CommonVoice/ASR/transducer/hparams/train_fr.yaml,recipes/CommonVoice/ASR/transducer/common_voice_prepare.py,recipes/CommonVoice/ASR/transducer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0060,ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_fr_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-fr,,
recipe0061,ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_it_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0062,ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_en_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0063,ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_rw_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,,
recipe0064,Language-id,VoxLingua107,recipes/VoxLingua107/lang_id/train.py,recipes/VoxLingua107/lang_id/hparams/train_ecapa.yaml,recipes/VoxLingua107/lang_id/create_wds_shards.py,recipes/VoxLingua107/lang_id/README.md,https://drive.google.com/drive/folders/151QTW9oHVElLIkuzXjkuHpOCLNZF0Ufd?usp=sharing,https://huggingface.co/speechbrain/lang-id-voxlingua107-ecapa,,
recipe0065,G2P,LibriSpeech,recipes/LibriSpeech/G2P/train.py,recipes/LibriSpeech/G2P/hparams/hparams_g2p_rnn.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://drive.google.com/drive/folders/1jpVDz6Kqtl4qp3_dsuK767mjNlqkIxTH?usp=sharing,,,
recipe0066,LM,LibriSpeech,recipes/LibriSpeech/LM/train.py,recipes/LibriSpeech/LM/hparams/transformer.yaml,recipes/LibriSpeech/LM/librispeech_prepare.py,recipes/LibriSpeech/LM/README.md,https://drive.google.com/drive/folders/1CCsGfq0mbHTvOVL7cJRl6hwmXDQB2Xcy?usp=sharing https://drive.google.com/drive/folders/17Qa2-3Q9KF-8huxxH_oZGdEwz4igCJ4o?usp=sharing https://drive.google.com/drive/folders/1oCEAjYUyummzcQSkhCbl_3Vf2ozy0BXp?usp=sharing,,,
recipe0067,LM,LibriSpeech,recipes/LibriSpeech/LM/train.py,recipes/LibriSpeech/LM/hparams/RNNLM.yaml,recipes/LibriSpeech/LM/librispeech_prepare.py,recipes/LibriSpeech/LM/README.md,https://drive.google.com/drive/folders/1CCsGfq0mbHTvOVL7cJRl6hwmXDQB2Xcy?usp=sharing https://drive.google.com/drive/folders/17Qa2-3Q9KF-8huxxH_oZGdEwz4igCJ4o?usp=sharing https://drive.google.com/drive/folders/1oCEAjYUyummzcQSkhCbl_3Vf2ozy0BXp?usp=sharing,,,
recipe0068,Tokenizer,LibriSpeech,recipes/LibriSpeech/Tokenizer/train.py,recipes/LibriSpeech/Tokenizer/hparams/1K_unigram_subword_bpe.yaml,recipes/LibriSpeech/Tokenizer/librispeech_prepare.py,recipes/LibriSpeech/Tokenizer/README.md,https://drive.google.com/drive/folders/1NcsYx5ER-Zlv7bRxtwBrefuYxaEO4nY3?usp=sharing,,,
recipe0069,Tokenizer,LibriSpeech,recipes/LibriSpeech/Tokenizer/train.py,recipes/LibriSpeech/Tokenizer/hparams/5K_unigram_subword_bpe.yaml,recipes/LibriSpeech/Tokenizer/librispeech_prepare.py,recipes/LibriSpeech/Tokenizer/README.md,https://drive.google.com/drive/folders/1NcsYx5ER-Zlv7bRxtwBrefuYxaEO4nY3?usp=sharing,,,
recipe0070,ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/conformer_small.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://drive.google.com/drive/folders/1sM3_PksmGQZMxXPibp7W7mQfPXFdHqc5?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <350, epoch: 10]"
recipe0071,ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/transformer.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://drive.google.com/drive/folders/1sM3_PksmGQZMxXPibp7W7mQfPXFdHqc5?usp=sharing,https://huggingface.co/speechbrain/asr-transformer-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=350, epoch: 10]"
recipe0072,ASR,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_1000.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/19mAyMR1ITSb83Anhds4n694PLwKD47yf?usp=sharing https://drive.google.com/drive/folders/15uUZ21HYnw4KyOPW3tx8bLrS9RoBZfS7?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]"
recipe0073,ASR,LibriSpeech,recipes/LibriSpeech/ASR/seq2seq/train.py,recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_5000.yaml,recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py,recipes/LibriSpeech/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/19mAyMR1ITSb83Anhds4n694PLwKD47yf?usp=sharing https://drive.google.com/drive/folders/15uUZ21HYnw4KyOPW3tx8bLrS9RoBZfS7?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-transformerlm-librispeech,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=18.5, epoch: 10]"
recipe0074,ASR,LibriSpeech,recipes/LibriSpeech/ASR/transducer/train.py,recipes/LibriSpeech/ASR/transducer/hparams/train.yaml,recipes/LibriSpeech/ASR/transducer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transducer/README.md,https://drive.google.com/drive/folders/17kEW0crU3tyP-8-u5TeoFom4ton_B-j2?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer_ASR_train.txt,save/lm.ckpt,save/tokenizer.ckpt] performance_check=[train_log.txt, train loss, <=400, epoch: 10]"
recipe0075,ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,https://drive.google.com/drive/folders/1pg0QzW-LqAISG8Viw_lUTGjXwOqh7gkl?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=[tests/samples/annotation/ASR_train.csv] --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train_with_wav2vec.py,wer_ASR_train.txt,save/label_encoder.txt] performance_check=[train_log.txt, train loss, <3.5, epoch: 10]"
recipe0076,Speech_Translation,Fisher-Callhome-Spanish,recipes/Fisher-Callhome-Spanish/ST/transformer/train.py,recipes/Fisher-Callhome-Spanish/ST/transformer/hparams/conformer.yaml,recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py,recipes/Fisher-Callhome-Spanish/README.md,https://drive.google.com/drive/folders/1wd4iWuFimZBanBDeZSPFjxM1m4LovXdb?usp=sharing https://drive.google.com/drive/folders/1hlMOy1yutwkcXgKIW7tMa5WEe1ixhLaU?usp=sharing,,,
recipe0077,Speech_Translation,Fisher-Callhome-Spanish,recipes/Fisher-Callhome-Spanish/ST/transformer/train.py,recipes/Fisher-Callhome-Spanish/ST/transformer/hparams/transformer.yaml,recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py,recipes/Fisher-Callhome-Spanish/README.md,https://drive.google.com/drive/folders/1wd4iWuFimZBanBDeZSPFjxM1m4LovXdb?usp=sharing https://drive.google.com/drive/folders/1hlMOy1yutwkcXgKIW7tMa5WEe1ixhLaU?usp=sharing,,,
recipe0078,Tokenizer,Fisher-Callhome-Spanish,recipes/Fisher-Callhome-Spanish/Tokenizer/train.py,recipes/Fisher-Callhome-Spanish/Tokenizer/hparams/train_bpe_1k.yaml,recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py,recipes/Fisher-Callhome-Spanish/README.md,,,,
recipe0079,SoundClassification,UrbanSound8k,recipes/UrbanSound8k/SoundClassification/train.py,recipes/UrbanSound8k/SoundClassification/hparams/train_ecapa_tdnn.yaml,recipes/UrbanSound8k/SoundClassification/urbansound8k_prepare.py,recipes/UrbanSound8k/README.md,https://drive.google.com/drive/folders/1sItfg_WNuGX6h2dCs8JTGq2v2QoNTaUg?usp=sharing,https://huggingface.co/speechbrain/urbansound8k_ecapa,,
recipe0080,VAD,LibriParty,recipes/LibriParty/VAD/train.py,recipes/LibriParty/VAD/hparams/train.yaml,recipes/LibriParty/VAD/libriparty_prepare.py,recipes/LibriParty/VAD/README.md,https://drive.google.com/drive/folders/1YLYGuiyuTH0D7fXOOp6cMddfQoM74o-Y?usp=sharing,https://huggingface.co/speechbrain/vad-crdnn-libriparty,,
recipe0081,Language-id,CommonLanguage,recipes/CommonLanguage/lang_id/train.py,recipes/CommonLanguage/lang_id/hparams/train_ecapa_tdnn.yaml,recipes/CommonLanguage/lang_id/common_language_prepare.py,recipes/CommonLanguage/lang_id/README.md,https://drive.google.com/drive/folders/1btxc_H27AP_f6u4X47FM0LSteUdzhfFR?usp=sharing,https://huggingface.co/speechbrain/lang-id-commonlanguage_ecapa,,
recipe0082,Emotion_recognition,IEMOCAP,recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py,recipes/IEMOCAP/emotion_recognition/hparams/train_with_wav2vec2.yaml,recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py,recipes/IEMOCAP/README.md,https://drive.google.com/drive/u/0/folders/11iZkcxvXYPnhf1yfYO_WVfRpGbN6HmNw https://drive.google.com/drive/u/0/folders/1hCL2vCQe2WS5wv5LU7JYkh7QSHNH9m4d https://drive.google.com/drive/u/0/folders/1m8xggbhbsXHedMbF6dNVkNEW1bfGTjvi,https://huggingface.co/speechbrain/emotion-recognition-wav2vec2-IEMOCAP/,,
recipe0083,Emotion_recognition,IEMOCAP,recipes/IEMOCAP/emotion_recognition/train.py,recipes/IEMOCAP/emotion_recognition/hparams/train.yaml,recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py,recipes/IEMOCAP/README.md,https://drive.google.com/drive/u/0/folders/11iZkcxvXYPnhf1yfYO_WVfRpGbN6HmNw https://drive.google.com/drive/u/0/folders/1hCL2vCQe2WS5wv5LU7JYkh7QSHNH9m4d https://drive.google.com/drive/u/0/folders/1m8xggbhbsXHedMbF6dNVkNEW1bfGTjvi,,,
recipe0084,Alignment,TIMIT,recipes/TIMIT/Alignment/train.py,recipes/TIMIT/Alignment/hparams/train.yaml,recipes/TIMIT/Alignment/timit_prepare.py,recipes/TIMIT/Alignment/README.md ,https://drive.google.com/drive/folders/1fXu7JAVUYxZLosH05iBTEPrJyVSCjNRi?usp=sharing,,,
recipe0085,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq/train_with_wav2vec2.py,recipes/TIMIT/ASR/seq2seq/hparams/train_with_wav2vec2.yaml,recipes/TIMIT/ASR/seq2seq/timit_prepare.py,recipes/TIMIT/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_train.json --test_annotation=tests/samples/annotation/ASR_train.json --output_neurons=47 --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train_with_wav2vec2.py,wer.txt,save/label_encoder.txt] performance_check=[train_log.txt, train loss, <=4, epoch: 10]"
recipe0086,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq/train.py,recipes/TIMIT/ASR/seq2seq/hparams/train.yaml,recipes/TIMIT/ASR/seq2seq/timit_prepare.py,recipes/TIMIT/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_train.json --test_annotation=tests/samples/annotation/ASR_train.json --output_neurons=47 --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer.txt,save/label_encoder.txt] performance_check=[train_log.txt, train loss, <=6, epoch: 10]"
recipe0087,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/save_teachers.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/save_teachers.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0088,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea8.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0089,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea1.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0090,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea5.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0091,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea3.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0092,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea6.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0093,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea2.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0094,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea0.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0095,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea7.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0096,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea4.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0097,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_teacher.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/teachers/tea9.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0098,ASR,TIMIT,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_kd.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/hparams/train_kd.yaml,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/timit_prepare.py,recipes/TIMIT/ASR/seq2seq_knowledge_distillation/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0099,ASR,TIMIT,recipes/TIMIT/ASR/transducer/train_wav2vec.py,recipes/TIMIT/ASR/transducer/hparams/train_wav2vec.yaml,recipes/TIMIT/ASR/transducer/timit_prepare.py,recipes/TIMIT/ASR/transducer/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,,
recipe0100,ASR,TIMIT,recipes/TIMIT/ASR/transducer/train.py,recipes/TIMIT/ASR/transducer/hparams/train.yaml,recipes/TIMIT/ASR/transducer/timit_prepare.py,recipes/TIMIT/ASR/transducer/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,--data_folder=tests/samples/ASR/ --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_train.json --test_annotation=tests/samples/annotation/ASR_train.json --output_neurons=44 --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer.txt,save/label_encoder.txt] performance_check=[train_log.txt, train loss, <=300, epoch: 10]"
recipe0101,ASR,TIMIT,recipes/TIMIT/ASR/CTC/train.py,recipes/TIMIT/ASR/CTC/hparams/train.yaml,recipes/TIMIT/ASR/CTC/timit_prepare.py,recipes/TIMIT/ASR/CTC/README.md,https://drive.google.com/drive/folders/1ZcME-Wf4stlzW3j_iJ3zGDCkSy1V_Wjs?usp=sharing,,--data_folder=tests/samples/ASR/  --train_annotation=tests/samples/annotation/ASR_train.json --valid_annotation=tests/samples/annotation/ASR_train.json --test_annotation=tests/samples/annotation/ASR_train.json --output_neurons=44 --number_of_epochs=10 --skip_prep=True,"file_exists=[env.log,hyperparams.yaml,log.txt,train_log.txt,train.py,wer.txt,save/label_encoder.txt] performance_check=[train_log.txt, train loss, <=12, epoch: 10]"
recipe0102,Separation,WHAMandWHAMR,recipes/WHAMandWHAMR/separation/train.py,recipes/WHAMandWHAMR/separation/hparams/sepformer-whamr.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/separation/README.md,https://drive.google.com/drive/folders/1m1xfx2ojf7qgOyscJVVCQFRY0VRl0rdi?usp=sharing,https://huggingface.co/speechbrain/sepformer-wham,,
recipe0103,Separation,WHAMandWHAMR,recipes/WHAMandWHAMR/separation/train.py,recipes/WHAMandWHAMR/separation/hparams/sepformer-wham.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/separation/README.md,https://drive.google.com/drive/folders/1dIAT8hZxvdJPZNUb8Zkk3BuN7GZ9-mZb?usp=sharing,https://huggingface.co/speechbrain/sepformer-whamr https://huggingface.co/speechbrain/sepformer-whamr16k,,
recipe0104,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,https://drive.google.com/drive/folders/1V0KwkEfWwomZ0Vjox0BTnQ694_uxgu8G?usp=sharing,https://huggingface.co/speechbrain/sepformer-whamr-enhancement,,
recipe0105,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr-16k-DM.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,,,,
recipe0106,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/cnntransformer-whamr-DM.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,,,,
recipe0107,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/cnntransformer-wham-DM.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,,,,
recipe0108,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/dprnn-whamr-DM.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,,,,
recipe0109,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr-16k.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,,,,
recipe0110,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/convtasnet-whamr-DM.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,,,,
recipe0111,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/sepformer-wham.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,https://drive.google.com/drive/folders/1bbQvaiN-R79M697NnekA7Rr0jIYtO6e3?usp=sharing,https://huggingface.co/speechbrain/sepformer-wham-enhancement,,
recipe0112,Enhancement,WHAMandWHAMR,recipes/WHAMandWHAMR/enhancement/train.py,recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr-DM.yaml,recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py,recipes/WHAMandWHAMR/enhancement/README.md,,,,
recipe0113,Tokenizer,SLURP,recipes/SLURP/Tokenizer/train.py,recipes/SLURP/Tokenizer/hparams/tokenizer_bpe58.yaml,recipes/SLURP/Tokenizer/prepare.py,recipes/SLURP/README.md,https://drive.google.com/drive/folders/103t4_zqBZNqa_gGlIfteIs8_mdKhn3Rd?usp=sharing https://drive.google.com/drive/folders/1LpcuFldRo_Va1OCGp1bLNdiaC7AQNJOb?usp=sharing,,,
recipe0114,SLU,SLURP,recipes/SLURP/direct/train_with_wav2vec2.py,recipes/SLURP/direct/hparams/train_with_wav2vec2.yaml,recipes/SLURP/direct/prepare.py,recipes/SLURP/README.md,https://drive.google.com/drive/folders/103t4_zqBZNqa_gGlIfteIs8_mdKhn3Rd?usp=sharing https://drive.google.com/drive/folders/1LpcuFldRo_Va1OCGp1bLNdiaC7AQNJOb?usp=sharing,https://huggingface.co/speechbrain/SLU-direct-SLURP-hubert-enc,,
recipe0115,SLU,SLURP,recipes/SLURP/direct/train.py,recipes/SLURP/direct/hparams/train.yaml,recipes/SLURP/direct/prepare.py,recipes/SLURP/README.md,https://drive.google.com/drive/folders/103t4_zqBZNqa_gGlIfteIs8_mdKhn3Rd?usp=sharing https://drive.google.com/drive/folders/1LpcuFldRo_Va1OCGp1bLNdiaC7AQNJOb?usp=sharing,,,
recipe0116,SLU,SLURP,recipes/SLURP/NLU/train.py,recipes/SLURP/NLU/hparams/train.yaml,recipes/SLURP/NLU/prepare.py,recipes/SLURP/README.md,https://drive.google.com/drive/folders/103t4_zqBZNqa_gGlIfteIs8_mdKhn3Rd?usp=sharing https://drive.google.com/drive/folders/1LpcuFldRo_Va1OCGp1bLNdiaC7AQNJOb?usp=sharing,,,
recipe0117,LM,minilibrispeech,templates/speech_recognition/LM/train.py,templates/speech_recognition/LM/RNNLM.yaml,templates/speech_recognition/mini_librispeech_prepare.py,templates/speech_recognition/README.md,,,,
recipe0118,Tokenizer,minilibrispeech,templates/speech_recognition/Tokenizer/train.py,templates/speech_recognition/Tokenizer/tokenizer.yaml,templates/speech_recognition/Tokenizer/mini_librispeech_prepare.py,templates/speech_recognition/Tokenizer/README.md,,,,
recipe0119,ASR,minilibrispeech,templates/speech_recognition/ASR/train.py,templates/speech_recognition/ASR/train.yaml,templates/speech_recognition/ASR/mini_librispeech_prepare.py,templates/speech_recognition/ASR/README.md,,,,
recipe0120,Enhancement,minilibrispeech,templates/enhancement/train.py,templates/enhancement/train.yaml,templates/enhancement/mini_librispeech_prepare.py,templates/enhancement/README.md,,,,
recipe0121,Speaker_recognition,minilibrispeech,templates/hyperparameter_optimization_speaker_id/train.py,templates/hyperparameter_optimization_speaker_id/train.yaml,templates/hyperparameter_optimization_speaker_id/mini_librispeech_prepare.py,templates/hyperparameter_optimization_speaker_id/README.md,,,,
recipe0122,Speaker_recognition,minilibrispeech,templates/speaker_id/train.py,templates/speaker_id/train.yaml,templates/speaker_id/mini_librispeech_prepare.py,templates/speaker_id/README.md,,,,
recipe0123,Separation,BinauralWSJ0Mix,recipes/BinauralWSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-independent.yaml,recipes/BinauralWSJ0Mix/separation/dynamic_mixing.py recipes/BinauralWSJ0Mix/prepare_data.py recipes/WSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/17FFwlIq6MQLHT9RXPgeYssti5TEeEXsx?usp=sharing,,,
recipe0124,Separation,BinauralWSJ0Mix,recipes/BinauralWSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-parallel.yaml,recipes/BinauralWSJ0Mix/separation/dynamic_mixing.py recipes/BinauralWSJ0Mix/prepare_data.py recipes/WSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/17FFwlIq6MQLHT9RXPgeYssti5TEeEXsx?usp=sharing,,,
recipe0125,Separation,BinauralWSJ0Mix,recipes/BinauralWSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-cross.yaml,recipes/BinauralWSJ0Mix/separation/dynamic_mixing.py recipes/BinauralWSJ0Mix/prepare_data.py recipes/WSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/17FFwlIq6MQLHT9RXPgeYssti5TEeEXsx?usp=sharing,,,
recipe0126,Separation,BinauralWSJ0Mix,recipes/BinauralWSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-parallel-noise.yaml,recipes/BinauralWSJ0Mix/separation/dynamic_mixing.py recipes/BinauralWSJ0Mix/prepare_data.py recipes/WSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/17FFwlIq6MQLHT9RXPgeYssti5TEeEXsx?usp=sharing,,,
recipe0127,Separation,BinauralWSJ0Mix,recipes/BinauralWSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-parallel-reverb.yaml,recipes/BinauralWSJ0Mix/separation/dynamic_mixing.py recipes/BinauralWSJ0Mix/prepare_data.py recipes/WSJ0Mix/separation/train.py,recipes/BinauralWSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/17FFwlIq6MQLHT9RXPgeYssti5TEeEXsx?usp=sharing,,,
recipe0128,TTS,LJSpeech,recipes/LJSpeech/TTS/tacotron2/train.py,recipes/LJSpeech/TTS/tacotron2/hparams/train.yaml,recipes/LJSpeech/TTS/ljspeech_prepare.py,recipes/LJSpeech/TTS/README.md,https://drive.google.com/drive/folders/1CbkXPvtLFVrRBeeuMnmTmNCyagNKO6uX?usp=sharing,https://huggingface.co/speechbrain/tts-tacotron2-ljspeech,,
recipe0129,TTS,LJSpeech,recipes/LJSpeech/TTS/vocoder/hifi_gan/train.py,recipes/LJSpeech/TTS/vocoder/hifi_gan/hparams/train.yaml,recipes/LJSpeech/TTS/ljspeech_prepare.py,recipes/LJSpeech/TTS/README.md,https://drive.google.com/drive/folders/19sLwV7nAsnUuLkoTu5vafURA9Fo2WZgG?usp=sharing,https://huggingface.co/speechbrain/tts-hifigan-ljspeech,,
recipe0130,ASR,Dvoice,recipes/DVoice/ASR/CTC/train_with_wav2vec2.py,recipes/DVoice/ASR/CTC/hparams/train_sw_with_wav2vec.yaml,recipes/DVoice/ASR/CTC/dvoice_prepare.py,recipes/DVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/1vNT7RjRuELs7pumBHmfYsrOp9m46D0ym?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-dvoice-swahili,,
recipe0131,ASR,Dvoice,recipes/DVoice/ASR/CTC/train_with_wav2vec2.py,recipes/DVoice/ASR/CTC/hparams/train_fon_with_wav2vec.yaml,recipes/DVoice/ASR/CTC/dvoice_prepare.py,recipes/DVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/1vNT7RjRuELs7pumBHmfYsrOp9m46D0ym?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-dvoice-fongbe,,
recipe0132,ASR,Dvoice,recipes/DVoice/ASR/CTC/train_with_wav2vec2.py,recipes/DVoice/ASR/CTC/hparams/train_amh_with_wav2vec.yaml,recipes/DVoice/ASR/CTC/dvoice_prepare.py,recipes/DVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/1vNT7RjRuELs7pumBHmfYsrOp9m46D0ym?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-dvoice-amharic,,
recipe0133,ASR,Dvoice,recipes/DVoice/ASR/CTC/train_with_wav2vec2.py,recipes/DVoice/ASR/CTC/hparams/train_dar_with_wav2vec.yaml,recipes/DVoice/ASR/CTC/dvoice_prepare.py,recipes/DVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/1vNT7RjRuELs7pumBHmfYsrOp9m46D0ym?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-dvoice-darija,,
recipe0134,ASR,Dvoice,recipes/DVoice/ASR/CTC/train_with_wav2vec2.py,recipes/DVoice/ASR/CTC/hparams/train_wol_with_wav2vec.yaml,recipes/DVoice/ASR/CTC/dvoice_prepare.py,recipes/DVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/1vNT7RjRuELs7pumBHmfYsrOp9m46D0ym?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-dvoice-wolof,,
recipe0135,ASR,Dvoice,recipes/DVoice/ASR/CTC/train_with_wav2vec2.py,recipes/DVoice/ASR/CTC/hparams/train_multi_with_wav2vec.yaml,recipes/DVoice/ASR/CTC/dvoice_prepare.py,recipes/DVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/1vNT7RjRuELs7pumBHmfYsrOp9m46D0ym?usp=sharing,,,
recipe0136,Separation,WSJ0Mix,recipes/WSJ0Mix/separation/train.py,recipes/WSJ0Mix/separation/hparams/resepformer.yaml,recipes/WSJ0Mix/separation/dynamic_mixing.py,recipes/WSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/1rXOyPQ7OZZMUzg7wrP1Zsa_fjFKMqaeu?usp=sharing,https://huggingface.co/speechbrain/resepformer-wsj02mix,,
recipe0137,Separation,WSJ0Mix,recipes/WSJ0Mix/separation/train.py,recipes/WSJ0Mix/separation/hparams/skim.yaml,recipes/WSJ0Mix/separation/dynamic_mixing.py,recipes/WSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/12HqVPpMXY-OOMsZ3xTAtkN7kk5TZ2YaL?usp=sharing,https://huggingface.co/speechbrain/resepformer-wsj02mix,,
recipe0138,Command_recognition,Google-speech-commands,recipes/Google-speech-commands/train.py,recipes/Google-speech-commands/hparams/xvect_leaf.yaml,recipes/Google-speech-commands/prepare_GSC.py,recipes/Google-speech-commands/README.md,https://drive.google.com/drive/folders/18AaNWrFUtr5OggwZxV7X7ZXvv2aQ4iMh?usp=sharing,,,
recipe0139,Command_recognition,Google-speech-commands,recipes/Google-speech-commands/train.py,recipes/Google-speech-commands/hparams/xvect_leaf.yaml,recipes/Google-speech-commands/prepare_GSC.py,recipes/Google-speech-commands/README.md,https://drive.google.com/drive/folders/18AaNWrFUtr5OggwZxV7X7ZXvv2aQ4iMh?usp=sharing,,,
recipe0140,G2P,LibriSpeech,recipes/LibriSpeech/G2P/train.py,recipes/LibriSpeech/G2P/hparams/hparams_g2p_transformer.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://drive.google.com/drive/folders/1lbSjCKUit8H3FCzaDJmfBDJOkcDRH3XI?usp=sharing,,,
recipe0141,G2P,LibriSpeech,recipes/LibriSpeech/G2P/train_lm.py,recipes/LibriSpeech/G2P/hparams/hparams_lm_rnn.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://drive.google.com/drive/folders/1Zv8SNYIXzboFatSRpmoNgRyVXl_6ucir?usp=sharing,,,
recipe0142,G2P,LibriSpeech,recipes/LibriSpeech/G2P/train_lm.py,recipes/LibriSpeech/G2P/hparams/hparams_lm_transformer.yaml,recipes/LibriSpeech/G2P/librispeech_prepare.py,recipes/LibriSpeech/G2P/README.md,https://drive.google.com/drive/folders/1MPceslDRVKW7sk1Q6W6nSaWETEAqp5t5?usp=sharing,,,
recipe0143,ASR,LibriSpeech,recipes/LibriSpeech/ASR/transformer/train.py,recipes/LibriSpeech/ASR/transformer/hparams/conformer.yaml,recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py,recipes/LibriSpeech/ASR/transformer/README.md,https://drive.google.com/drive/folders/15uUZ21HYnw4KyOPW3tx8bLrS9RoBZfS7?usp=sharing,,,
recipe0144,ST,Tamasheq-French,recipes/IWSLT22_lowresource/train.py,recipes/IWSLT22_lowresource/hparams/train_w2v2_st.yaml,recipes/IWSLT22_lowresource/prepare_iwslt22.py,recipes/IWSLT22_lowresource/README.md,,,,
recipe0145,self-supervised-learning,LibriSpeech,recipes/LibriSpeech/self-supervised-learning/wav2vec2/train_sb_wav2vec2.py,recipes/LibriSpeech/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml,recipes/LibriSpeech/self-supervised-learning/wav2vec2/librispeech_prepare.py,recipes/LibriSpeech/self-supervised-learning/wav2vec2/README.md,,,,
recipe0146,ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_sb_wav2vec.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,,
recipe0147,ASR,LibriSpeech,recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py,recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec.yaml,recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py,recipes/LibriSpeech/ASR/CTC/README.md,,,,
recipe0148,Separation,WSJ0Mix,recipes/WSJ0Mix/separation/train.py,recipes/WSJ0Mix/separation/hparams/sepformer-conformerintra.yaml,recipes/WSJ0Mix/separation/dynamic_mixing.py,recipes/WSJ0Mix/separation/README.md,https://drive.google.com/drive/folders/1NcB7pKj7qWzDaI3ScDOyQwJLvRdW9rfl,
recipe0149,ASR,AISHELL-1,recipes/AISHELL-1/ASR/CTC/train_with_wav2vec.py,recipes/AISHELL-1/ASR/CTC/hparams/train_with_wav2vec.yaml,recipes/AISHELL-1/ASR/CTC/aishell_prepare.py,recipes/AISHELL-1/ASR/CTC/README.md,https://drive.google.com/drive/folders/1GTB5IzQPl57j-0I1IpmvKg722Ti4ahLz?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-ctc-aishell,,
recipe0150,TTS,AISHELL-1,recipes/LibriTTS/vocoder/hifigan/train.py,recipes/LibriTTS/vocoder/hifigan/hparams/train.yaml,recipes/LibriTTS/libritts_prepare.py,recipes/LibriTTS/README.md,https://drive.google.com/drive/folders/1cImFzEonNYhetS9tmH9R_d0EFXXN0zpn?usp=sharing,https://huggingface.co/speechbrain/tts-hifigan-libritts-16kHz,,
recipe0151,ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_de_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/19G2Zm8896QSVDqVfs7PS_W86-K0-5xeC?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-de,,