# ############################################################################
# Auido Tokenizer: Fairseq HuBERT
# Extraction: Librispeech 960h
# Authors: Adel Moumen 2025
# ############################################################################
# Seed needs to be set at top of yaml, before objects with parameters are made
# HF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 python extract.py hparams/fairseq_hubert.yaml --data_folder $SLURM_TMPDIR/LibriSpeech/ --precision bf16 --batch_size 1 --save_folder $SCRATCH/results/hubert25hzl11
seed: 1986
__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]
output_folder: !ref results/hubert
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/extraction_log.txt

# Distributed extraction
rank: 0
num_shards: 1

# Data files
data_folder: !PLACEHOLDER  # e.g., /path/to/LibriSpeech
train_splits: ["train-clean-100", "train-clean-360", "train-other-500"]
dev_splits: ["dev-clean"]
test_splits: ["dev-clean", "test-clean", "test-other"]
skip_prep: False
train_csv: !ref <output_folder>/train.csv
valid_csv: !ref <output_folder>/dev-clean.csv
test_csv:
  - !ref <output_folder>/test-clean.csv
  - !ref <output_folder>/test-other.csv

batch_size: 1
num_workers: 8
src_key: wav
id_key: id

# Dataloader options
dataloader_opts:
  batch_size: !ref <batch_size>
  shuffle: True
  num_workers: !ref <num_workers>

####################### Model parameters ###########################
vocab_size: 500
num_codebooks: 1
sample_rate: 16000
save_embedding: False

tokenizer: !new:utils.tokenizer_interface.FairseqHuBERTTokenizer
  layer: 11
  feat_extractor_path: /scratch/adelmou/models/hubert25hz/mhubert_base_25hz_cp_mls_cv_sp_fisher.pt
  km_path: /scratch/adelmou/models/hubert25hz/mhubert_base_25hz_cp_mls_cv_sp_fisher_L11_km500.bin

tokens_extractor: !new:utils.tokens.TokensExtractor
  tokenizer: !ref <tokenizer>
  sample_rate: !ref <sample_rate>
  src_key: !ref <src_key>
  id_key: !ref <id_key>
  dataloader_opts: !ref <dataloader_opts>
  rank: !ref <rank>
  num_shards: !ref <num_shards>
