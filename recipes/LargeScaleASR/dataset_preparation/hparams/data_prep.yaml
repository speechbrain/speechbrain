# ############################################################################
# Data preparation parameters for The LargeScaleASR Set.
# Authors:  Titouan Parcollet
# ############################################################################

# This variable decides what this recipe will do. See the .py file for all the
# possible actions
ACTION_TO_PERFORM: !PLACEHOLDER

# We only take this amount of hours from libriheavy. Can be changed.
LIBRIHEAVY_CUTOFF_HOURS: 11000

####################### Data paths ###########################################

# Path where everything will be stored.
DATASET_ROOT: /your/path/to/largescaleasr

# Path of the original source datasets. The path here are given just to show
# where they should point to. Please replace then with the appropriate ones.
VOXPOPULI_PATH: /your/path/to/voxpopuli/transcribed_data/en
CV_PATH: /your/path/to/CommonVoice/cv-corpus-18.0-2024-06-14/en
LIBRISPEECH_PATH: /your/path/to/LibriSpeech/
LIBRILIGHT_PATH: /your/path/to/Libri-Light/large
LIBRIHEAVY_TRAIN_JSON: /your/path/to/libriheavy/libriheavy_cuts_large.jsonl.gz
LIBRIHEAVY_DEV_JSON: /your/path/to/libriheavy/libriheavy_cuts_dev.jsonl.gz
LIBRIHEAVY_TEST_JSON: /your/path/to/libriheavy/libriheavy_cuts_test_clean.jsonl.gz
PEOPLES_SPEECH_PATH: /your/path/to/peoplesspeech # HuggingFace data
YODAS_PATH: /your/path/to/yodas # HuggingFace data

####################### CSV paths ###########################################

# Paths of csv generated by individual dataset preparation. These are combined
# to form The LargeScaleASR Set manifests.
VOX_TRAIN_PATH: !ref <DATASET_ROOT>/manifests/vox_train.csv
CV_TRAIN_PATH: !ref <DATASET_ROOT>/manifests/commonvoice_train.csv
LIBRIHEAVY_TRAIN_PATH: !ref <DATASET_ROOT>/manifests/libriheavy_train.csv
PEOPLE_TRAIN_PATH: !ref <DATASET_ROOT>/manifests/people_speech_train.csv
YODAS_TRAIN_PATH: !ref <DATASET_ROOT>/manifests/yodas_train.csv

# Paths of the LargeScaleASR Set csvs (final ones).
TLS_TRAIN_LARGE_PATH: !ref <DATASET_ROOT>/manifests/largescaleasr_large_train.csv
TLS_TRAIN_MEDIUM_PATH: !ref <DATASET_ROOT>/manifests/largescaleasr_medium_train.csv
TLS_TRAIN_SMALL_PATH: !ref <DATASET_ROOT>/manifests/largescaleasr_small_train.csv
TLS_TRAIN_CLEAN_PATH: !ref <DATASET_ROOT>/manifests/largescaleasr_clean_train.csv

# Validation and test variables (same than above, but only for validation and test)

VOX_VAL_PATH: !ref <DATASET_ROOT>/manifests/vox_dev.csv
LIBRI_VAL_PATH: !ref <DATASET_ROOT>/manifests/libri_dev-other.csv
CV_VAL_PATH: !ref <DATASET_ROOT>/manifests/commonvoice_dev.csv
VOX_TEST_PATH: !ref <DATASET_ROOT>/manifests/vox_test.csv
LIBRI_TEST_PATH: !ref <DATASET_ROOT>/manifests/libri_test-other.csv
CV_TEST_PATH: !ref <DATASET_ROOT>/manifests/commonvoice_test.csv
YODAS_VAL_PATH: !ref <DATASET_ROOT>/manifests/yodas_dev_cleaned.csv
YODAS_TEST_PATH: !ref <DATASET_ROOT>/manifests/yodas_test_cleaned.csv

TLS_VAL_PATH: !ref <DATASET_ROOT>/manifests/largescaleasr_dev.csv
TLS_TEST_PATH: !ref <DATASET_ROOT>/manifests/largescaleasr_test.csv

####################### Parquet variables #####################################

# This variables are used when generating the HuggingFace sharded version of
# the dataset. This will duplicate the dataset! Need storage!
PARQUET_SUBSET: large # large/medium/small/clean
PARQUET_SPLIT: train # train/dev/test
PARQUET_OUTPUT_FOLDER: /your/path/to/largescaleasr_sharded/large # Any path.
PARQUET_ORIG_CSV: !ref <DATASET_ROOT>/manifests/largescaleasr_large_train.csv
PARQUET_CSV_OUTPUT_FOLDER: /your/path/to/largescaleasr_sharded/
MAX_SHARD_SIZE: 500MB
