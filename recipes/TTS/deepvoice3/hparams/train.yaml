# ################################
# Model: DeepVoice3 - Single Speaker
# Training
# Authors:
# * Artem Ploujnikov 2021
# ################################
seed: 64
__set_seed: !apply:torch.manual_seed [!ref <seed>]

embed_dim: 256
speaker_embed_dim: None
batch_size: 32
use_speaker_embed: False
n_vocab: 128
dropout: 0.05
mel_dim: 80
outputs_per_step: 1
downsample_step: 4
time_upsampling: !ref <downsample_step> // <outputs_per_step>
max_target_len: 1024
masked_loss_weight: 0.5
binary_divergence_weight: 0.1
priority_freq: 3000
priority_freq_weight: 0.0
source_sample_rate: 48000
sample_rate: 22050
trim_threshold: -30.
window_ahead: 3
window_backward: 1
encoder_in_std_mul: 1.0
encoder_mid_std_mul: 2.0
encoder_out_std_mul: 4.0
encoder_conv_kernel_size: 5
encoder_conv_channels: 128
encoder_conv_dilation: 1
encoder_out_kernel_size: 1
preattention_out_channels: 256
preattention_conv_channels: 256
preattention_conv_kernel_size: 5
preattention_in_std_mul: 1.0
preattention_mid_std_mul: 2.0
preattention_high_std_mul: 4.0
decoder_in_dim: !ref <mel_dim>
decoder_conv_std_mul: 1.0
decoder_conv_channels: 256
decoder_conv_kernel_size: 5
decoder_query_position_rate: 1.0
decoder_key_position_rate: 1.29
decoder_max_positions: 512
decoder_key_projection: false
decoder_value_projection: false
decoder_low_std_mul: 1.0
decoder_mid_std_mul: 4.0
decoder_high_std_mul: 4.0
converter_conv_channels: 256
converter_conv_channels_bottom: !ref 2 * <converter_conv_channels>
converter_conv_kernel_size: 5
converter_out_kernel_size: 1
converter_in_std_mul: 1.0
converter_mid_std_mul: 4.0
converter_out_std_mul: 4.0
converter_in_dim: !ref <decoder_conv_channels>
linear_dim: 513
n_fft: 1024
max_mel_len: !ref <decoder_max_positions> // <downsample_step>
max_input_len: 128
max_output_len: 512
hop_length: 256
mel_downsample_step: 4
min_level_db: -100
ref_level_db: 20
pad_linear: !ref <max_output_len>
pad_mel: !ref <max_mel_len>
guided_attention_sigma: 0.2
padding_idx: 0
embedding_weight_std: 0.1
force_monotonic_attention: true
use_decoder_state_for_postnet_input: true
freeze_embedding: false
lr: 0.0005
lr_warmup_steps: 4000
max_grad_norm: 0.1
number_of_epochs: 50
ckpt_frequency: 100
progress_samples: true
progress_samples_incremental: true
progress_sample_path: !ref <output_folder>/samples
progress_samples_interval: 100
overfit_test: false
overfit_test_iterations: 1
train_data_path: ../datasets/mockdata/fake_vctk_1ex
valid_data_path: ../datasets/mockdata/fake_vctk_1ex
save_for_pretrained: true



output_folder: !ref ./results/tts/deepvoice/<seed>
save_folder: !ref <output_folder>/save
pretrained_path: !ref <save_folder>
train_log: !ref <output_folder>/train_log.txt
tensorboard_logs: !ref <output_folder>/logs

inverse_spectrogram_n_iter: 1024

tokens: ABCDEFGHIJKLMNOPQRSTUVWXYZ.,!-


encoder: !new:speechbrain.lobes.models.synthesis.deepvoice3.Encoder
  n_vocab: !ref <n_vocab>
  embed_dim: !ref <embed_dim>
  padding_idx: !ref <padding_idx>
  use_speaker_embed: !ref <use_speaker_embed>
  speaker_embed_dim: !ref <speaker_embed_dim>
  dropout: !ref <dropout>
  embedding_weight_std: !ref <embedding_weight_std>
  convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <embed_dim>
      out_channels: !ref <encoder_conv_channels>
      kernel_size: 1
      dilation: 1
      padding: valid
      dropout: 0.
      std_mul: !ref <encoder_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &encoder_conv
      in_channels: !ref <encoder_conv_channels>
      out_channels: !ref <encoder_conv_channels>
      kernel_size: !ref <encoder_conv_kernel_size>
      dilation: !ref <encoder_conv_dilation>
      padding: same
      dropout: !ref <dropout>
      std_mul: !ref <encoder_mid_std_mul>
      residual: true
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 9
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 27
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 9
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 27
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <encoder_conv_channels>
      out_channels: !ref <embed_dim>
      kernel_size: 1
      padding: valid
      dilation: !ref <encoder_conv_dilation>
      std_mul: !ref <encoder_out_std_mul>
      dropout: !ref <dropout>


decoder: !new:speechbrain.lobes.models.synthesis.deepvoice3.Decoder
    embed_dim: !ref <embed_dim>
    in_dim: !ref <mel_dim>
    r: !ref <outputs_per_step>
    use_speaker_embed: !ref <use_speaker_embed>
    speaker_embed_dim: !ref <speaker_embed_dim>
    dropout: !ref <dropout>
    max_positions: !ref <decoder_max_positions>
    in_channels: !ref <preattention_conv_channels>
    force_monotonic_attention: !ref <force_monotonic_attention>
    query_position_rate: !ref <decoder_query_position_rate>
    key_position_rate: !ref <decoder_key_position_rate>
    preattention:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <mel_dim> * <outputs_per_step>
      out_channels: !ref <preattention_conv_channels>
      kernel_size: 1
      dilation: 1
      padding: valid
      dropout: !ref <dropout>
      std_mul: !ref <preattention_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &decoder_preattention_conv
      in_channels: !ref <preattention_conv_channels>
      out_channels: !ref <preattention_conv_channels>
      kernel_size: !ref <preattention_conv_kernel_size>
      padding: null
      dropout: !ref <dropout>
      std_mul: !ref <preattention_mid_std_mul>
      causal: true
      residual: true
      dilation: 1
      use_speaker_embed: !ref <use_speaker_embed>
      speaker_embed_dim: !ref <speaker_embed_dim>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_preattention_conv
      std_mul: !ref <preattention_high_std_mul>
      use_speaker_embed: !ref <use_speaker_embed>
      speaker_embed_dim: !ref <speaker_embed_dim>
      dilation: 3
    convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &decoder_conv
      in_channels: !ref <decoder_conv_channels>
      out_channels: !ref <decoder_conv_channels>
      kernel_size: !ref <decoder_conv_kernel_size>
      dropout: !ref <dropout>
      std_mul: !ref <decoder_low_std_mul>
      causal: true
      residual: false
      dilation: 1
      use_speaker_embed: !ref <use_speaker_embed>
      speaker_embed_dim: !ref <speaker_embed_dim>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_preattention_conv
      dilation: 3
      std_mul: !ref <decoder_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_preattention_conv
      dilation: 9
      std_mul: !ref <decoder_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_preattention_conv
      dilation: 27
      std_mul: !ref <decoder_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_preattention_conv
      dilation: 1
      std_mul: !ref <decoder_mid_std_mul>
    attention:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionLayer &attention
      conv_channels: !ref <decoder_conv_channels>
      embed_dim: !ref <embed_dim>
      dropout: !ref <dropout>
      window_ahead: !ref <window_ahead>
      window_backward: !ref <window_backward>
      key_projection: !ref <decoder_key_projection>
      value_projection: !ref <decoder_value_projection>
    - null
    - null
    - null
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionLayer
      <<: *attention
    output: !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <decoder_conv_channels>
      out_channels: !ref <mel_dim> * <outputs_per_step>
      kernel_size: 1
      dilation: 1
      padding: valid
      dropout: 0.
      std_mul: !ref <encoder_in_std_mul>


converter: !new:speechbrain.lobes.models.synthesis.deepvoice3.Converter
  use_speaker_embed: !ref <use_speaker_embed>
  in_dim: !ref <converter_in_dim>
  out_dim: !ref <linear_dim>
  dropout: !ref <dropout>
  convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <converter_in_dim>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 1
      dilation: 1
      padding: valid
      dropout: 0.
      std_mul: !ref <converter_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.TransposeConvBlock
      in_channels: !ref <converter_in_dim>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 2
      dropout: 0.
      padding: valid
      stride: 2
      std_mul: !ref <converter_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &converter_in_conv
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 3
      dropout: 0.
      causal: false
      residual: true
      dilation: 1
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_in_conv
      dilation: 3
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.TransposeConvBlock
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 2
      dropout: 0.
      padding: valid
      stride: 2
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_in_conv
      dilation: 1
      std_mul: !ref <converter_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_in_conv
      dilation: 3
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &converter_conv
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref <converter_conv_channels>
      kernel_size: !ref <converter_conv_kernel_size>
      dropout: !ref <dropout>
      causal: false
      residual: true
      dilation: 1
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      dilation: 3
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref 2 * <converter_conv_channels>
      kernel_size: 1
      padding: valid
      dilation: 1
      dropout: !ref <dropout>
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      in_channels: !ref  <converter_conv_channels_bottom>
      out_channels: !ref <converter_conv_channels_bottom>
      dilation: 1
      residual: true
      std_mul: !ref <converter_mid_std_mul> // 2
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      in_channels: !ref <converter_conv_channels_bottom>
      out_channels: !ref <converter_conv_channels_bottom>
      dilation: 3
      residual: true
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <converter_conv_channels_bottom>
      out_channels: !ref <linear_dim>
      kernel_size: 1
      padding: valid
      dilation: 1
      dropout: !ref <dropout>
      std_mul: !ref <converter_out_std_mul>


seq2seq: !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionSeq2Seq
  encoder: !ref <encoder>
  decoder: !ref <decoder>


model: !new:speechbrain.lobes.models.synthesis.deepvoice3.TTSModel
  seq2seq: !ref <seq2seq>
  postnet: !ref <converter>
  mel_dim: !ref <mel_dim>
  linear_dim: !ref <linear_dim>
  use_speaker_embed: !ref <use_speaker_embed>
  speaker_embed_dim: !ref <speaker_embed_dim>
  use_decoder_state_for_postnet_input: !ref <use_decoder_state_for_postnet_input>
  freeze_embedding: !ref <freeze_embedding>

model_output_keys:
  - mel
  - linear
  - attention
  - done

pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
  loadables:
    model: !ref <model>
  paths:
    model: !ref <pretrained_path>/model.ckpt

compute_cost: !new:speechbrain.lobes.models.synthesis.deepvoice3.Loss
  linear_dim: !ref <linear_dim>
  downsample_step: !ref <downsample_step>
  outputs_per_step: !ref <outputs_per_step>
  masked_loss_weight: !ref <masked_loss_weight>
  binary_divergence_weight: !ref <binary_divergence_weight>
  priority_freq: !ref <priority_freq>
  priority_freq_weight: !ref <priority_freq_weight>
  sample_rate: !ref <sample_rate>
  guided_attention_sigma: !ref <guided_attention_sigma>

lr_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler
  lr_initial: !ref <lr>
  n_warmup_steps: !ref <lr_warmup_steps>

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <number_of_epochs>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <save_folder>
  recoverables:
    model: !ref <model>
    counter: !ref <epoch_counter>
    lr_annealing: !ref <lr_annealing>

modules:
  model: !ref <model>

datasets:
  train:
    path: !ref <train_data_path>
  valid:
    path: !ref <train_data_path>

opt_class: !name:torch.optim.Adam
  lr: !ref <lr>

dataloader_options:
  batch_size: !ref <batch_size>
  shuffle: True

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>
tensorboard_train_logger: !new:speechbrain.utils.train_logger.TensorboardLogger
  save_dir: !ref <tensorboard_logs>

loggers:
  - !ref <train_logger>
  - !ref <tensorboard_train_logger>

test_frozen_batch: false

train_pipeline:
  output_keys:
      - text_sequences
      - input_lengths
      - text_positions
      - sig_trimmed
  steps:
    - !name:speechbrain.lobes.models.synthesis.dataio.audio_pipeline
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.trim
      takes: sig
      provides: sig_trimmed
      threshold: !ref <trim_threshold>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.text_encoder
      max_input_len: !ref <max_input_len>
      tokens: !ref <tokens>

features_pipeline:
  output_keys:
      - text_sequences
      - input_lengths
      - text_positions
      - mel
      - target_lengths
      - frame_positions
      - done
      - linear
  steps:
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.resample
      takes: sig_trimmed
      provides: sig_resampled
      orig_freq: !ref <source_sample_rate>
      new_freq: !ref <sample_rate>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.mel_spectrogram
      takes: sig_resampled
      provides: mel_raw
      hop_length: !ref <hop_length>
      n_mels: !ref <mel_dim>
      n_fft: !ref <n_fft>
      power: 1
      sample_rate: !ref <sample_rate>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.normalize_spectrogram
      takes: mel_raw
      provides: mel_norm
      min_level_db: !ref <min_level_db>
      ref_level_db: !ref <ref_level_db>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.pad_spectrogram
      takes: mel_norm
      provides: mel_pad
      outputs_per_step: !ref <outputs_per_step>
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.downsample_spectrogram
      takes: mel_pad
      provides: mel
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.frame_positions
      max_output_len: !ref <max_mel_len> * <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.spectrogram
      takes: sig_resampled
      provides: linear_raw
      n_fft: !ref <n_fft>
      hop_length: !ref <hop_length>
      power: 1
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.normalize_spectrogram
      takes: linear_raw
      provides: linear_norm
      min_level_db: !ref <min_level_db>
      ref_level_db: !ref <ref_level_db>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.pad_spectrogram
      takes: linear_norm
      provides: linear
      outputs_per_step: !ref <outputs_per_step>
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.done
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.target_lengths


encode_pipeline:
  batch: false
  output_keys:
  - text_sequences
  - text_positions
  - input_lengths
  steps:
  - !apply:speechbrain.lobes.models.synthesis.deepvoice3.text_encoder
    takes: txt
    max_input_len: !ref <max_input_len>
    tokens: !ref <tokens>


decode_pipeline:
  steps:
  - !apply:speechbrain.lobes.models.synthesis.deepvoice3.denormalize_spectrogram
    takes: linear
    provides: linear_denorm
    min_level_db: !ref <min_level_db>
    ref_level_db: !ref <ref_level_db>
  - !apply:speechbrain.lobes.models.synthesis.dataio.transpose_spectrogram
    takes: linear_denorm
    provides: linear_denorm_flip
  - !apply:speechbrain.lobes.models.synthesis.dataio.inverse_spectrogram
    takes: linear_denorm_flip
    provides: wav
    n_fft: !ref <n_fft>
    n_iter: !ref <inverse_spectrogram_n_iter>
    hop_length: !ref <hop_length>
    power: 1

