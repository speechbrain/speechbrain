seed: 1234
ignored_key: !!python/object/apply:torch.manual_seed [!ref <seed>]

# Data files
data_folder: !PLACEHOLDER
csv_train: !ref <data_folder>/train.csv
csv_valid: !ref <data_folder>/dev.csv
csv_test: !ref <data_folder>/test.csv

# Neural Parameters
N_epochs: 10
N_batch: 1
lr: 0.004

train_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_train>
    batch_size: !ref <N_batch>
    csv_read: [wav, phn]
    replacements:
        $data_folder: !ref <data_folder>

valid_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_valid>
    batch_size: !ref <N_batch>
    csv_read: [wav, phn]
    replacements:
        $data_folder: !ref <data_folder>

test_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_test>
    csv_read: [wav, phn]
    replacements:
        $data_folder: !ref <data_folder>

compute_features: !new:speechbrain.lobes.features.mfcc.MFCC

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: global

rnn: !new:speechbrain.nnet.RNN.RNN
    rnn_type: gru
    n_neurons: 256
    nonlinearity: tanh
    num_layers: 2
    dropout: 0.15
    bidirectional: True

lin: !new:speechbrain.nnet.linear.Linear
    n_neurons: 43  # 42 phonemes + 1 blank
    bias: False

softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

compute_cost: !new:speechbrain.nnet.losses.ComputeCost
    cost_type: ctc
    blank_index: 42

optimizer: !new:speechbrain.nnet.optimizers.Optimize
    optimizer_type: adam
    learning_rate: !ref <lr>
